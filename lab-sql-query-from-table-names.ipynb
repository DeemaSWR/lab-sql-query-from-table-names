{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a57394-53dd-47cd-a5e7-6e7122bbb0f6",
   "metadata": {},
   "source": [
    "# SQL query from table names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f",
   "metadata": {
    "id": "86bc2813-763c-49f2-9f5d-e1f87a20556f"
   },
   "source": [
    "In This notebook we are going to test if using just the name of the table, and a shord definition of its contect we can use a model like GTP3.5-Turbo to select which tables are necessary to create a SQL Order to answer the user petition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023",
   "metadata": {
    "id": "7fbbdf5b-4d7f-4496-8f40-9d15ea46d023"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148",
   "metadata": {
    "id": "e480bbfb-9a80-4ea6-b792-067e63ae3148"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_OAI(user_message):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "    context = []\n",
    "    context.append({'role':'system', \"content\": user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=context,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
   "metadata": {
    "id": "6d5d2bdc-d822-4ed8-815e-b3f223730f15",
    "outputId": "61068bf0-41e3-40d9-b453-b76da5b0f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       table                                         definition\n",
      "0  employees         Employee information, name, position, etc.\n",
      "1     salary                       Salary details for each year\n",
      "2    studies  Educational studies, institution name, type of...\n"
     ]
    }
   ],
   "source": [
    "#Definition of the tables.\n",
    "import pandas as pd\n",
    "\n",
    "# Table and definitions sample\n",
    "data = {\n",
    "    'table': ['employees', 'salary', 'studies'],\n",
    "    'definition': [\n",
    "        'Employee information, name, position, etc.',\n",
    "        'Salary details for each year',\n",
    "        'Educational studies, institution name, type of studies, level'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95",
   "metadata": {
    "id": "009e681c-d95d-4c9c-b044-5bfd76e3ad95"
   },
   "outputs": [],
   "source": [
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for index, row in df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
   "metadata": {
    "id": "fe03ac25-8d02-4cd1-99a1-be4220c6fd2d",
    "outputId": "c1f3aab1-5f26-48fe-fcf9-3780120f5aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employees: Employee information, name, position, etc.\n",
      "salary: Salary details for each year\n",
      "studies: Educational studies, institution name, type of studies, level\n"
     ]
    }
   ],
   "source": [
    "print(text_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c",
   "metadata": {
    "id": "c7e275ae-f20d-4134-b9b6-d8677dfb544c"
   },
   "outputs": [],
   "source": [
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names in a json format.\n",
    "###User Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Replace with actual question\n",
    "user_question = \"List employees who studied at a university.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e",
   "metadata": {
    "id": "b1cb5957-2df2-4e5e-9e6a-ace955c9817e"
   },
   "outputs": [],
   "source": [
    "# Creating the prompt\n",
    "pqt1 = prompt_question_tables.format(tables=text_tables, question=user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
   "metadata": {
    "id": "10d30f2b-6c23-4fd6-8038-840fba784cce",
    "outputId": "9924022c-7b2b-4ec8-e2c2-75bc1c745151",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"studies\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b",
   "metadata": {
    "id": "57e07083-be8f-4cd0-95bd-c4b909422c6b"
   },
   "outputs": [],
   "source": [
    "pqt3 = prompt_question_tables.format(\n",
    "    tables=text_tables,\n",
    "    question=\"How many employees have a Master's degree?\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
   "metadata": {
    "id": "a0eeb79e-caf1-4f48-9897-168d95d2ae37",
    "outputId": "81d77115-9cad-4284-a228-5368bb9aa6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"tables\": [\"employees\", \"studies\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(return_OAI(pqt3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3",
   "metadata": {
    "id": "321bb9a2-4937-4e9a-a31b-7049cb8f5aa3"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try a few versions if you have time\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong\n",
    " - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e9cb333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario 1 Response: To address the user's question, the following tables would be necessary to query with SQL:\n",
      "1. employees\n",
      "2. salary\n",
      "3. studies\n",
      "Scenario 2 Response: To address the user's question, the following tables would be necessary to query with SQL:\n",
      "1. employees\n",
      "2. studies\n",
      "\n",
      "These tables will provide the necessary information to identify employees working in the 'Engineering' department who have attended Ivy League universities.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load OpenAI API Key from environment\n",
    "load_dotenv(find_dotenv())\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Function to interact with OpenAI GPT model\n",
    "def query_gpt(prompt):\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    context = [{\"role\": \"system\", \"content\": prompt}]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=context,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Define table descriptions using pandas DataFrame\n",
    "data = {\n",
    "    'table': ['employees', 'salary', 'studies'],\n",
    "    'definition': [\n",
    "        'Information about employees, including names, roles, and departments.',\n",
    "        'Annual salary details for each employee.',\n",
    "        'Educational background, institutions attended, degree types.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert table information into formatted string\n",
    "text_tables = '\\n'.join([f\"{row['table']}: {row['definition']}\" for _, row in df.iterrows()])\n",
    "\n",
    "# Create a prompt with table definitions and user's scenario\n",
    "prompt_question_tables = \"\"\"\n",
    "Given the following tables and their content definitions,\n",
    "###Tables\n",
    "{tables}\n",
    "\n",
    "Tell me which tables would be necessary to query with SQL to address the user's question below.\n",
    "Return the table names clearly.\n",
    "###User Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "# Example Scenario (Version 1)\n",
    "scenario1 = \"List all employees who earned more than $100,000 in 2023 and their educational qualifications.\"\n",
    "prompt1 = prompt_question_tables.format(tables=text_tables, question=scenario1)\n",
    "\n",
    "# Query GPT for scenario 1\n",
    "response1 = query_gpt(prompt1)\n",
    "\n",
    "# Print GPT response\n",
    "print(\"Scenario 1 Response:\", response1)\n",
    "\n",
    "# Example Query (Version 2)\n",
    "scenario2 = \"Identify employees working in the 'Engineering' department who have attended Ivy League universities.\"\n",
    "prompt2 = prompt_question_tables.format(tables=text_tables, question=scenario2)\n",
    "\n",
    "# Query GPT for scenario 2\n",
    "response2 = query_gpt(prompt2)\n",
    "\n",
    "# Print GPT response\n",
    "print(\"Scenario 2 Response:\", response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ce24f3",
   "metadata": {},
   "source": [
    "## Summary Report on GPT Prompting with SQL Queries\n",
    "\n",
    "## Findings\n",
    "\n",
    "Two different SQL-related scenarios were tested to evaluate how clearly and accurately GPT could identify the required database tables based on provided descriptions.\n",
    "\n",
    "## Scenario 1\n",
    "The query asked GPT to identify tables necessary for listing employees earning above $100,000 in 2023 and their educational qualifications. GPT correctly identified the tables:\n",
    "- `employees`\n",
    "- `salary`\n",
    "- `studies`\n",
    "\n",
    "The response was precise, accurate, and complete, aligning well with expectations.\n",
    "\n",
    "## Scenario 2\n",
    "The query requested GPT to identify employees from the 'Engineering' department who attended Ivy League universities. GPT correctly identified:\n",
    "- `employees`\n",
    "- `studies`\n",
    "\n",
    "This scenario demonstrated GPT's strong contextual understanding and ability to filter relevant tables based on content descriptions.\n",
    "\n",
    "## Variations and Issues\n",
    "No significant hallucinations or incorrect identifications occurred in these specific test cases. Both prompts were clear enough that GPT responded accurately. However, GPT might occasionally misinterpret ambiguous queries, highlighting the importance of clear and explicit wording in prompts.\n",
    "\n",
    "## Lessons Learned\n",
    "- Clearly structured and detailed table descriptions significantly improve GPT's ability to provide accurate responses.\n",
    "- GPT reliably identifies relevant tables if scenarios are straightforward and clearly described.\n",
    "- Ambiguous queries or insufficient context might lead to inaccuracies; thus, precision in prompting is essential.\n",
    "\n",
    "Overall, GPT effectively handled these scenarios, demonstrating strong potential as a supportive tool in database query planning and preliminary analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76491424",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "IronhackCamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
